#!/usr/bin/env python3
"""
å¢žå¼·ç‰ˆå”ä½œæª¢æ¸¬ç®—æ³•
æå‡å”ä½œä»»å‹™æª¢æ¸¬æº–ç¢ºçŽ‡åˆ° 90%+
"""

import re
from typing import List, Dict, Tuple
from dataclasses import dataclass
from enum import Enum


class CollaborationPattern(Enum):
    """å”ä½œæ¨¡å¼é¡žåž‹"""
    SEQUENTIAL = "sequential"      # é †åºåŸ·è¡Œï¼šå…ˆåšAï¼Œç„¶å¾ŒåšB
    PARALLEL = "parallel"         # ä¸¦è¡ŒåŸ·è¡Œï¼šåŒæ™‚åšAå’ŒB
    CONDITIONAL = "conditional"   # æ¢ä»¶åŸ·è¡Œï¼šå¦‚æžœAï¼Œå‰‡åšB
    ITERATIVE = "iterative"      # è¿­ä»£åŸ·è¡Œï¼šé‡è¤‡åšAç›´åˆ°B


@dataclass
class CollaborationSignal:
    """å”ä½œä¿¡è™Ÿ"""
    pattern: CollaborationPattern
    confidence: float
    keywords: List[str]
    context: str


class EnhancedCollaborationDetector:
    """å¢žå¼·ç‰ˆå”ä½œæª¢æ¸¬å™¨"""
    
    def __init__(self):
        self.name = "Enhanced Collaboration Detector"
        self.version = "2.0.0"
        
        # å¤šèªžè¨€å”ä½œé—œéµè©žåº«
        self.collaboration_keywords = {
            # é †åºåŸ·è¡Œé—œéµè©ž
            "sequential": {
                "en": ["then", "after", "next", "followed by", "subsequently", "afterwards", "later", "once"],
                "zh": ["ç„¶å¾Œ", "æŽ¥è‘—", "ä¹‹å¾Œ", "éš¨å¾Œ", "æŽ¥ä¸‹ä¾†", "å®Œæˆå¾Œ", "åšå®Œ", "å…ˆ", "å†"],
                "zh_traditional": ["ç„¶å¾Œ", "æŽ¥è‘—", "ä¹‹å¾Œ", "éš¨å¾Œ", "æŽ¥ä¸‹ä¾†", "å®Œæˆå¾Œ", "åšå®Œ", "å…ˆ", "å†"]
            },
            
            # ä¸¦è¡ŒåŸ·è¡Œé—œéµè©ž
            "parallel": {
                "en": ["and", "also", "simultaneously", "at the same time", "meanwhile", "concurrently", "both"],
                "zh": ["ä¸¦ä¸”", "åŒæ™‚", "é‚„è¦", "ä¹Ÿè¦", "ä¸€é‚Š", "ä¸€èµ·", "åŒæ­¥"],
                "zh_traditional": ["ä¸¦ä¸”", "åŒæ™‚", "é‚„è¦", "ä¹Ÿè¦", "ä¸€é‚Š", "ä¸€èµ·", "åŒæ­¥"]
            },
            
            # æ¢ä»¶åŸ·è¡Œé—œéµè©ž
            "conditional": {
                "en": ["if", "when", "unless", "provided that", "in case", "should", "depending on"],
                "zh": ["å¦‚æžœ", "ç•¶", "å‡å¦‚", "è¦æ˜¯", "å€˜è‹¥", "è‹¥æ˜¯", "æ ¹æ“š"],
                "zh_traditional": ["å¦‚æžœ", "ç•¶", "å‡å¦‚", "è¦æ˜¯", "å€˜è‹¥", "è‹¥æ˜¯", "æ ¹æ“š"]
            },
            
            # è¿­ä»£åŸ·è¡Œé—œéµè©ž
            "iterative": {
                "en": ["repeat", "until", "while", "for each", "iterate", "loop", "continue"],
                "zh": ["é‡è¤‡", "ç›´åˆ°", "å¾ªç’°", "æ¯å€‹", "æŒçºŒ", "åè¦†", "ç¹¼çºŒ"],
                "zh_traditional": ["é‡è¤‡", "ç›´åˆ°", "å¾ªç’°", "æ¯å€‹", "æŒçºŒ", "åè¦†", "ç¹¼çºŒ"]
            }
        }
        
        # å‹•ä½œè©žåº«ï¼ˆè¡¨ç¤ºå¯åŸ·è¡Œçš„ä»»å‹™ï¼‰
        self.action_verbs = {
            "en": ["search", "find", "write", "create", "build", "make", "analyze", "download", 
                   "save", "send", "read", "process", "generate", "execute", "run", "test"],
            "zh": ["æœå°‹", "æŸ¥æ‰¾", "å¯«", "å‰µå»º", "å»ºç«‹", "è£½ä½œ", "åˆ†æž", "ä¸‹è¼‰", 
                   "ä¿å­˜", "ç™¼é€", "è®€å–", "è™•ç†", "ç”Ÿæˆ", "åŸ·è¡Œ", "é‹è¡Œ", "æ¸¬è©¦"],
            "zh_traditional": ["æœå°‹", "æŸ¥æ‰¾", "å¯«", "å‰µå»º", "å»ºç«‹", "è£½ä½œ", "åˆ†æž", "ä¸‹è¼‰", 
                              "ä¿å­˜", "ç™¼é€", "è®€å–", "è™•ç†", "ç”Ÿæˆ", "åŸ·è¡Œ", "é‹è¡Œ", "æ¸¬è©¦"]
        }
        
        # å¦å®šè©žï¼ˆé™ä½Žå”ä½œå¯èƒ½æ€§ï¼‰
        self.negation_words = {
            "en": ["only", "just", "simply", "merely", "single", "alone", "individual"],
            "zh": ["åª", "åƒ…", "å–®ç´”", "å–®ç¨", "å€‹åˆ¥", "ç¨è‡ª", "å”¯ä¸€"],
            "zh_traditional": ["åª", "åƒ…", "å–®ç´”", "å–®ç¨", "å€‹åˆ¥", "ç¨è‡ª", "å”¯ä¸€"]
        }
    
    def detect_language(self, text: str) -> str:
        """ç°¡å–®çš„èªžè¨€æª¢æ¸¬"""
        # æª¢æ¸¬ä¸­æ–‡å­—ç¬¦
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        total_chars = len(text.replace(' ', ''))
        
        if chinese_chars / max(total_chars, 1) > 0.3:
            return "zh"
        return "en"
    
    def extract_sentences(self, text: str) -> List[str]:
        """æå–å¥å­"""
        # æŒ‰æ¨™é»žç¬¦è™Ÿåˆ†å‰²
        sentences = re.split(r'[.!?ã€‚ï¼ï¼Ÿï¼›;]', text)
        return [s.strip() for s in sentences if s.strip()]
    
    def count_action_verbs(self, text: str, language: str) -> int:
        """è¨ˆç®—å‹•ä½œè©žæ•¸é‡"""
        text_lower = text.lower()
        action_verbs = self.action_verbs.get(language, self.action_verbs["en"])
        
        count = 0
        for verb in action_verbs:
            if verb in text_lower:
                count += 1
        
        return count
    
    def detect_collaboration_patterns(self, text: str) -> List[CollaborationSignal]:
        """æª¢æ¸¬å”ä½œæ¨¡å¼"""
        language = self.detect_language(text)
        text_lower = text.lower()
        signals = []
        
        for pattern_type, keywords_dict in self.collaboration_keywords.items():
            keywords = keywords_dict.get(language, keywords_dict["en"])
            
            found_keywords = []
            for keyword in keywords:
                if keyword in text_lower:
                    found_keywords.append(keyword)
            
            if found_keywords:
                # è¨ˆç®—ç½®ä¿¡åº¦
                confidence = len(found_keywords) / len(keywords)
                
                # æ ¹æ“šæ¨¡å¼é¡žåž‹èª¿æ•´ç½®ä¿¡åº¦
                if pattern_type == "sequential" and any(word in text_lower for word in ["then", "ç„¶å¾Œ", "æŽ¥è‘—"]):
                    confidence += 0.2
                elif pattern_type == "parallel" and any(word in text_lower for word in ["and", "ä¸¦ä¸”", "åŒæ™‚"]):
                    confidence += 0.15
                
                confidence = min(1.0, confidence)
                
                signal = CollaborationSignal(
                    pattern=CollaborationPattern(pattern_type),
                    confidence=confidence,
                    keywords=found_keywords,
                    context=text[:100] + "..." if len(text) > 100 else text
                )
                signals.append(signal)
        
        return signals
    
    def analyze_sentence_structure(self, text: str) -> Dict[str, float]:
        """åˆ†æžå¥å­çµæ§‹"""
        language = self.detect_language(text)
        
        analysis = {
            "action_verb_count": 0,
            "sentence_count": 0,
            "avg_sentence_length": 0,
            "complexity_score": 0,
            "negation_penalty": 0
        }
        
        sentences = self.extract_sentences(text)
        analysis["sentence_count"] = len(sentences)
        
        if sentences:
            total_length = sum(len(s.split()) for s in sentences)
            analysis["avg_sentence_length"] = total_length / len(sentences)
        
        # è¨ˆç®—å‹•ä½œè©žæ•¸é‡
        analysis["action_verb_count"] = self.count_action_verbs(text, language)
        
        # è¨ˆç®—è¤‡é›œåº¦åˆ†æ•¸
        if analysis["action_verb_count"] >= 2:
            analysis["complexity_score"] += 0.3
        if analysis["sentence_count"] >= 2:
            analysis["complexity_score"] += 0.2
        if analysis["avg_sentence_length"] > 10:
            analysis["complexity_score"] += 0.1
        
        # æª¢æŸ¥å¦å®šè©ž
        negation_words = self.negation_words.get(language, self.negation_words["en"])
        for word in negation_words:
            if word in text.lower():
                analysis["negation_penalty"] += 0.1
        
        return analysis
    
    def calculate_collaboration_score(self, text: str) -> Tuple[float, Dict]:
        """è¨ˆç®—å”ä½œåˆ†æ•¸ï¼ˆå„ªåŒ–ç‰ˆï¼‰"""
        # æª¢æ¸¬å”ä½œæ¨¡å¼
        signals = self.detect_collaboration_patterns(text)

        # åˆ†æžå¥å­çµæ§‹
        structure = self.analyze_sentence_structure(text)

        # åŸºç¤Žåˆ†æ•¸
        base_score = 0.0

        # å”ä½œä¿¡è™Ÿåˆ†æ•¸ï¼ˆæé«˜æ¬Šé‡ï¼‰
        if signals:
            signal_score = max(signal.confidence for signal in signals)
            base_score += signal_score * 0.8  # å¾ž 0.6 æé«˜åˆ° 0.8

        # å‹•ä½œè©žæ•¸é‡çŽå‹µï¼ˆæ›´ç©æ¥µçš„çŽå‹µï¼‰
        action_count = structure["action_verb_count"]
        if action_count >= 2:
            base_score += 0.4  # å¾ž 0.2 æé«˜åˆ° 0.4
        if action_count >= 3:
            base_score += 0.2  # é¡å¤–çŽå‹µ

        # çµæ§‹è¤‡é›œåº¦åˆ†æ•¸
        base_score += structure["complexity_score"] * 0.2  # é™ä½Žæ¬Šé‡

        # ç‰¹æ®Šæ¨¡å¼æª¢æ¸¬
        text_lower = text.lower()

        # å¼·å”ä½œæŒ‡æ¨™
        strong_indicators = [
            "and then", "ç„¶å¾Œ", "æŽ¥è‘—", "followed by", "after that",
            "and also", "ä¸¦ä¸”", "åŒæ™‚", "simultaneously",
            "multiple", "several", "both", "å„ç¨®", "å¤šå€‹"
        ]

        for indicator in strong_indicators:
            if indicator in text_lower:
                base_score += 0.3
                break

        # é€£æŽ¥è©žæª¢æ¸¬
        connectors = ["and", "then", "also", "plus", "ä¸¦", "é‚„", "ä¹Ÿ", "åˆ"]
        connector_count = sum(1 for conn in connectors if conn in text_lower)
        if connector_count >= 2:
            base_score += 0.2

        # å¦å®šè©žæ‡²ç½°
        base_score -= structure["negation_penalty"]

        # å–®ä¸€å‹•ä½œæ‡²ç½°
        if action_count == 1 and not signals:
            base_score -= 0.3

        # ç¢ºä¿åˆ†æ•¸åœ¨ 0-1 ç¯„åœå…§
        final_score = max(0.0, min(1.0, base_score))

        # è©³ç´°åˆ†æžçµæžœ
        analysis_details = {
            "signals": signals,
            "structure": structure,
            "base_score": base_score,
            "final_score": final_score,
            "is_collaborative": final_score >= 0.5
        }

        return final_score, analysis_details
    
    def detect_collaborative_task(self, text: str, threshold: float = 0.5) -> bool:
        """
        æª¢æ¸¬æ˜¯å¦ç‚ºå”ä½œä»»å‹™ï¼ˆä¸»è¦æŽ¥å£ï¼‰
        
        Args:
            text: è¼¸å…¥æ–‡æœ¬
            threshold: åˆ¤æ–·é–¾å€¼ï¼ˆé»˜èª 0.5ï¼‰
            
        Returns:
            bool: æ˜¯å¦ç‚ºå”ä½œä»»å‹™
        """
        score, _ = self.calculate_collaboration_score(text)
        return score >= threshold
    
    def get_detailed_analysis(self, text: str) -> Dict:
        """ç²å–è©³ç´°åˆ†æžçµæžœ"""
        score, details = self.calculate_collaboration_score(text)
        
        return {
            "text": text,
            "collaboration_score": score,
            "is_collaborative": score >= 0.5,
            "confidence": "high" if score >= 0.7 else "medium" if score >= 0.5 else "low",
            "detected_patterns": [signal.pattern.value for signal in details["signals"]],
            "key_indicators": [signal.keywords for signal in details["signals"]],
            "analysis_details": details
        }


def test_enhanced_detector():
    """æ¸¬è©¦å¢žå¼·ç‰ˆæª¢æ¸¬å™¨"""
    print("ðŸ§ª Testing Enhanced Collaboration Detector")
    print("=" * 50)
    
    detector = EnhancedCollaborationDetector()
    
    # æ¸¬è©¦ç”¨ä¾‹
    test_cases = [
        # æ˜Žç¢ºçš„å”ä½œä»»å‹™
        ("Search for Python tutorials and then write a script", True),
        ("Find the latest news and save it to a file", True),
        ("Write code, test it, and then deploy", True),
        ("æœå°‹è³‡æ–™ç„¶å¾Œåˆ†æžçµæžœ", True),
        ("å…ˆä¸‹è¼‰æ–‡ä»¶ï¼ŒæŽ¥è‘—è™•ç†æ•¸æ“š", True),
        
        # ä¸¦è¡Œå”ä½œä»»å‹™
        ("Search for tutorials and also download examples", True),
        ("Write code and simultaneously test it", True),
        ("åŒæ™‚æœå°‹å’Œåˆ†æžæ•¸æ“š", True),
        
        # æ¢ä»¶å”ä½œä»»å‹™
        ("If the file exists, then process it", True),
        ("When you find the data, analyze it", True),
        ("å¦‚æžœæ‰¾åˆ°çµæžœï¼Œå°±ä¿å­˜æ–‡ä»¶", True),
        
        # éžå”ä½œä»»å‹™
        ("Hello, how are you?", False),
        ("Just say hello", False),
        ("Only search for information", False),
        ("åƒ…åƒ…å•å€™ä¸€ä¸‹", False),
        ("å–®ç´”çš„æœå°‹", False),
        
        # é‚Šç•Œæƒ…æ³
        ("Search for information", False),  # å–®ä¸€å‹•ä½œ
        ("Write a simple script", False),   # å–®ä¸€å‹•ä½œ
        ("Create multiple files and organize them", True),  # å¤šå‹•ä½œ
    ]
    
    correct_predictions = 0
    total_tests = len(test_cases)
    
    print("ðŸ“‹ Test Results:")
    print("-" * 30)
    
    for text, expected in test_cases:
        analysis = detector.get_detailed_analysis(text)
        predicted = analysis["is_collaborative"]
        score = analysis["collaboration_score"]
        confidence = analysis["confidence"]
        
        is_correct = predicted == expected
        if is_correct:
            correct_predictions += 1
        
        status = "âœ…" if is_correct else "âŒ"
        print(f"{status} '{text[:40]}...'")
        print(f"   Expected: {expected}, Got: {predicted} (Score: {score:.2f}, {confidence})")
        
        if analysis["detected_patterns"]:
            print(f"   Patterns: {', '.join(analysis['detected_patterns'])}")
        
        print()
    
    accuracy = correct_predictions / total_tests * 100
    print("=" * 50)
    print(f"ðŸ“Š Overall Accuracy: {accuracy:.1f}% ({correct_predictions}/{total_tests})")
    
    if accuracy >= 90:
        print("ðŸŽ‰ EXCELLENT! Target accuracy achieved!")
    elif accuracy >= 80:
        print("âœ… GOOD! Close to target accuracy")
    else:
        print("âš ï¸  NEEDS IMPROVEMENT")
    
    return accuracy >= 90


if __name__ == "__main__":
    success = test_enhanced_detector()
    exit(0 if success else 1)
